# Map-ReduceåŸç†ä¸RAGæ£€ç´¢ä¼˜åŒ–

## ğŸ“‹ ç›®å½•
- [åŸºæœ¬æ¦‚å¿µ](#åŸºæœ¬æ¦‚å¿µ)
- [Map-Reduceå·¥ä½œæµç¨‹](#map-reduceå·¥ä½œæµç¨‹)
- [åœ¨RAGä¸­çš„åº”ç”¨](#åœ¨ragä¸­çš„åº”ç”¨)
- [å®ç°æ¶æ„](#å®ç°æ¶æ„)
- [æ€§èƒ½ä¼˜åŠ¿](#æ€§èƒ½ä¼˜åŠ¿)
- [ä½¿ç”¨ç¤ºä¾‹](#ä½¿ç”¨ç¤ºä¾‹)
- [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)
- [å¯¹æ¯”åˆ†æ](#å¯¹æ¯”åˆ†æ)

## åŸºæœ¬æ¦‚å¿µ

### ä»€ä¹ˆæ˜¯Map-Reduceï¼Ÿ

Map-Reduceæ˜¯ä¸€ç§åˆ†å¸ƒå¼è®¡ç®—ç¼–ç¨‹æ¨¡å‹ï¼Œæœ€åˆç”±Googleæå‡ºï¼Œç”¨äºå¤„ç†å¤§è§„æ¨¡æ•°æ®é›†ã€‚å®ƒå°†å¤æ‚çš„æ•°æ®å¤„ç†ä»»åŠ¡åˆ†è§£ä¸ºä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼š

- **Mapé˜¶æ®µ**ï¼šå°†è¾“å…¥æ•°æ®åˆ†å‰²æˆç‹¬ç«‹çš„å—ï¼Œå¹¶è¡Œå¤„ç†æ¯ä¸ªå—
- **Reduceé˜¶æ®µ**ï¼šæ”¶é›†Mapé˜¶æ®µçš„è¾“å‡ºç»“æœï¼Œè¿›è¡Œæ±‡æ€»å’Œæ•´åˆ

### æ ¸å¿ƒæ€æƒ³

```
è¾“å…¥æ•°æ® â†’ åˆ†å‰² â†’ å¹¶è¡Œå¤„ç† â†’ æ±‡æ€» â†’ æœ€ç»ˆç»“æœ
```

## Map-Reduceå·¥ä½œæµç¨‹

### 1. æ•°æ®åˆ†å‰²ï¼ˆSplitï¼‰
```
åŸå§‹Context: [item1, item2, item3, ..., itemN]
            â†“
åˆ†å‰²å: [chunk1, chunk2, chunk3, chunk4]
```

### 2. Mapé˜¶æ®µï¼ˆå¹¶è¡Œå¤„ç†ï¼‰
```
chunk1 â†’ LLMå¤„ç† â†’ result1
chunk2 â†’ LLMå¤„ç† â†’ result2  (å¹¶è¡Œæ‰§è¡Œ)
chunk3 â†’ LLMå¤„ç† â†’ result3
chunk4 â†’ LLMå¤„ç† â†’ result4
```

### 3. Reduceé˜¶æ®µï¼ˆç»“æœæ•´åˆï¼‰
```
[result1, result2, result3, result4] â†’ æ•´åˆå¤„ç† â†’ æœ€ç»ˆç­”æ¡ˆ
```

## åœ¨RAGä¸­çš„åº”ç”¨

### ä¼ ç»ŸRAGçš„é—®é¢˜

1. **é¡ºåºå¤„ç†é™åˆ¶**ï¼šå¿…é¡»é€ä¸€å¤„ç†æ¯ä¸ªcontextç‰‡æ®µ
2. **ä¸Šä¸‹æ–‡é•¿åº¦é™åˆ¶**ï¼šå•æ¬¡å¤„ç†çš„tokenæ•°é‡å—é™
3. **å¤„ç†æ•ˆç‡ä½**ï¼šæ— æ³•åˆ©ç”¨å¹¶è¡Œè®¡ç®—èƒ½åŠ›
4. **å“åº”æ—¶é—´é•¿**ï¼šç‰¹åˆ«æ˜¯åœ¨å¤„ç†å¤§é‡contextæ—¶

### Map-Reduce RAGçš„è§£å†³æ–¹æ¡ˆ

```mermaid
graph TD
    A[ç”¨æˆ·é—®é¢˜] --> B[Contextæ£€ç´¢]
    B --> C[Contextåˆ†å‰²]
    C --> D1[Chunk 1]
    C --> D2[Chunk 2]
    C --> D3[Chunk 3]
    C --> D4[Chunk 4]
    D1 --> E1[LLMå¤„ç†1]
    D2 --> E2[LLMå¤„ç†2]
    D3 --> E3[LLMå¤„ç†3]
    D4 --> E4[LLMå¤„ç†4]
    E1 --> F[ç»“æœæ•´åˆ]
    E2 --> F
    E3 --> F
    E4 --> F
    F --> G[æœ€ç»ˆç­”æ¡ˆ]
```

## å®ç°æ¶æ„

### æ ¸å¿ƒç»„ä»¶

#### 1. LLMMapReduceRunner
```python
class LLMMapReduceRunner(LLMCallMixin):
    """åŸºäºMap-Reduceç­–ç•¥çš„RAGæ£€ç´¢ä¼˜åŒ–å¤„ç†å™¨"""
    
    async def run_async(self, question: str, context: List[str], chunk_count: int = 4):
        # Mapé˜¶æ®µï¼šå¹¶è¡Œå¤„ç†
        context_chunks = self._split_context(context, chunk_count)
        map_tasks = [self._process_chunk_async(chunk, question, i+1) 
                    for i, chunk in enumerate(context_chunks)]
        map_results = await asyncio.gather(*map_tasks)
        
        # Reduceé˜¶æ®µï¼šç»“æœæ•´åˆ
        final_answer = await self._reduce_results(question, map_results)
        return final_answer
```

#### 2. Promptæ¨¡æ¿è®¾è®¡

**Mapæ¨¡æ¿**ï¼šä¸“æ³¨äºå•ä¸ªchunkçš„ä¿¡æ¯æå–
```python
MAP_TEMPLATE = """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¿¡æ¯åˆ†æå¸ˆï¼Œæ­£åœ¨å‚ä¸ä¸€ä¸ªåˆ†å¸ƒå¼é—®ç­”å¤„ç†è¿‡ç¨‹ã€‚
è¯·åŸºäºå½“å‰è¿™éƒ¨åˆ†ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œæä¾›ç›¸å…³çš„ç­”æ¡ˆç‰‡æ®µã€‚

å½“å‰å¤„ç†çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ (ç¬¬{chunk_index}éƒ¨åˆ†):
{context}

é—®é¢˜: {question}

è¯·åŸºäºå½“å‰è¿™éƒ¨åˆ†ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œæä¾›ç›¸å…³çš„ç­”æ¡ˆç‰‡æ®µï¼š
"""
```

**Reduceæ¨¡æ¿**ï¼šä¸“æ³¨äºä¿¡æ¯æ•´åˆå’Œå»é‡
```python
REDUCE_TEMPLATE = """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¿¡æ¯æ•´åˆä¸“å®¶ï¼Œéœ€è¦å°†å¤šä¸ªæ¥æºçš„ç­”æ¡ˆç‰‡æ®µæ•´åˆæˆå®Œæ•´ç­”æ¡ˆã€‚

åŸå§‹é—®é¢˜ï¼š{question}
ç­”æ¡ˆç‰‡æ®µï¼š{map_results}

è¯·å®Œæˆä»¥ä¸‹æ•´åˆä»»åŠ¡ï¼š
1. ä¿¡æ¯å»é‡ï¼šå»é™¤é‡å¤æˆ–ç›¸ä¼¼çš„ä¿¡æ¯
2. é€»è¾‘ç»„ç»‡ï¼šå°†ç›¸å…³ä¿¡æ¯æŒ‰é€»è¾‘é¡ºåºé‡æ–°ç»„ç»‡
3. å®Œæ•´æ€§æ£€æŸ¥ï¼šç¡®ä¿ç­”æ¡ˆå®Œæ•´å›ç­”äº†ç”¨æˆ·çš„é—®é¢˜

æ•´åˆåçš„å®Œæ•´ç­”æ¡ˆï¼š
"""
```

### å¹¶å‘æ§åˆ¶

```python
# ä½¿ç”¨ä¿¡å·é‡æ§åˆ¶å¹¶å‘æ•°é‡
semaphore = asyncio.Semaphore(MAX_CONCURRENT_REQUESTS)

async def limited_task(task):
    async with semaphore:
        return await task

map_results = await asyncio.gather(*[limited_task(task) for task in map_tasks])
```

## æ€§èƒ½ä¼˜åŠ¿

### 1. å¤„ç†é€Ÿåº¦æå‡

| ç­–ç•¥ | å¤„ç†æ–¹å¼ | æ—¶é—´å¤æ‚åº¦ | å®é™…åŠ é€Ÿæ¯” |
|------|----------|------------|------------|
| é¡ºåºå¤„ç† | ä¸²è¡Œ | O(n) | 1x |
| Map-Reduce | å¹¶è¡Œ | O(n/p) | æ¥è¿‘px (pä¸ºå¹¶è¡Œåº¦) |

### 2. èµ„æºåˆ©ç”¨ç‡

- **CPUåˆ©ç”¨ç‡**ï¼šå……åˆ†åˆ©ç”¨å¤šæ ¸å¤„ç†èƒ½åŠ›
- **ç½‘ç»œå¸¦å®½**ï¼šå¹¶è¡ŒAPIè°ƒç”¨ï¼Œæé«˜å¸¦å®½åˆ©ç”¨ç‡
- **å†…å­˜æ•ˆç‡**ï¼šåˆ†å—å¤„ç†ï¼Œé™ä½å•æ¬¡å†…å­˜å ç”¨

### 3. å¯æ‰©å±•æ€§

```python
# æ ¹æ®contextå¤§å°è‡ªåŠ¨è°ƒæ•´chunkæ•°é‡
def adaptive_chunk_count(context_size: int) -> int:
    if context_size <= 10:
        return 2
    elif context_size <= 50:
        return 4
    elif context_size <= 200:
        return 8
    else:
        return min(16, context_size // 25)
```

## ä½¿ç”¨ç¤ºä¾‹

### åŸºæœ¬ä½¿ç”¨

```python
from config import LLM_API_KEY, LLM_API_URL
from map_reduce.runner import LLMMapReduceRunner
import asyncio
import json

# åˆå§‹åŒ–runner
runner = LLMMapReduceRunner(llm_api_key=LLM_API_KEY, llm_api_url=LLM_API_URL)

# åŠ è½½çŸ¥è¯†åº“
with open("ai_agent_knowledge.json", "r", encoding="utf-8") as f:
    knowledge = json.load(f)

# æ‰§è¡ŒæŸ¥è¯¢
async def main():
    question = "ä»€ä¹ˆæ˜¯æ™ºèƒ½ä½“,èƒ½ç”¨åœ¨å“ªäº›é¢†åŸŸ?"
    result = await runner.run_async(question, knowledge, chunk_count=4)
    print(result)

asyncio.run(main())
```

### æ€§èƒ½ç»Ÿè®¡

```python
# è·å–æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯
stats = runner.get_performance_stats(knowledge, chunk_count=4)
print(f"æ€»contextæ•°é‡: {stats['total_context_items']}")
print(f"åˆ†å‰²chunkæ•°: {stats['chunk_count']}")
print(f"é¢„ä¼°åŠ é€Ÿæ¯”: {stats['estimated_parallel_speedup']}")
```

### æµå¼å¤„ç†

```python
# å®æ—¶æ˜¾ç¤ºå¤„ç†è¿›åº¦
result = await runner.run_async_stream(question, knowledge, chunk_count=4)
```

## æœ€ä½³å®è·µ

### 1. Chunkæ•°é‡é€‰æ‹©

```python
# æ¨èé…ç½®
CHUNK_COUNT_GUIDELINES = {
    "å°æ•°æ®é›†(< 20æ¡)": 2,
    "ä¸­æ•°æ®é›†(20-100æ¡)": 4,
    "å¤§æ•°æ®é›†(100-500æ¡)": 8,
    "è¶…å¤§æ•°æ®é›†(> 500æ¡)": 16
}
```

### 2. å¹¶å‘æ§åˆ¶

```python
# æ ¹æ®APIé™åˆ¶è°ƒæ•´å¹¶å‘æ•°
MAX_CONCURRENT_REQUESTS = 8  # é¿å…APIé™æµ
```

### 3. é”™è¯¯å¤„ç†

```python
async def robust_process_chunk(self, chunk, question, chunk_index):
    """å¸¦é‡è¯•æœºåˆ¶çš„chunkå¤„ç†"""
    max_retries = 3
    for attempt in range(max_retries):
        try:
            return await self._process_chunk_async(chunk, question, chunk_index)
        except Exception as e:
            if attempt == max_retries - 1:
                return f"ç‰‡æ®µ{chunk_index}å¤„ç†å¤±è´¥: {str(e)}"
            await asyncio.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
```

### 4. è´¨é‡æ§åˆ¶

```python
def validate_map_result(result: str) -> bool:
    """éªŒè¯Mapé˜¶æ®µç»“æœè´¨é‡"""
    return (
        len(result.strip()) > 10 and  # æœ€å°é•¿åº¦
        "æ— ç›¸å…³ä¿¡æ¯" not in result and  # æœ‰æ•ˆå†…å®¹
        len(result) < 2000  # æœ€å¤§é•¿åº¦é™åˆ¶
    )
```

## å¯¹æ¯”åˆ†æ

### Map-Reduce vs å…¶ä»–ç­–ç•¥

| ç‰¹æ€§ | Map-Reduce | Refine | Stuff | 
|------|------------|---------|-------|
| **å¤„ç†é€Ÿåº¦** | â­â­â­â­â­ | â­â­ | â­â­â­ |
| **ç­”æ¡ˆè´¨é‡** | â­â­â­â­ | â­â­â­â­â­ | â­â­â­ |
| **å¯æ‰©å±•æ€§** | â­â­â­â­â­ | â­â­â­ | â­ |
| **èµ„æºæ¶ˆè€—** | â­â­â­ | â­â­â­â­ | â­â­ |
| **å®ç°å¤æ‚åº¦** | â­â­â­ | â­â­ | â­â­â­â­â­ |

### ä½¿ç”¨åœºæ™¯æ¨è

1. **Map-Reduceé€‚ç”¨äº**ï¼š
   - å¤§é‡contextéœ€è¦å¤„ç†
   - å¯¹å“åº”é€Ÿåº¦è¦æ±‚é«˜
   - æœ‰å¹¶è¡Œå¤„ç†èƒ½åŠ›çš„ç¯å¢ƒ

2. **Refineé€‚ç”¨äº**ï¼š
   - å¯¹ç­”æ¡ˆè´¨é‡è¦æ±‚æé«˜
   - Contextä¹‹é—´æœ‰å¼ºä¾èµ–å…³ç³»
   - éœ€è¦æ¸è¿›å¼ä¼˜åŒ–ç­”æ¡ˆ

3. **Stuffé€‚ç”¨äº**ï¼š
   - Contextæ•°é‡å°‘ä¸”ç®€å•
   - éœ€è¦å¿«é€ŸåŸå‹å¼€å‘
   - å¯¹æ€§èƒ½è¦æ±‚ä¸é«˜

## æ€»ç»“

Map-Reduceç­–ç•¥é€šè¿‡å¹¶è¡Œå¤„ç†å’Œç»“æœæ•´åˆï¼Œæ˜¾è‘—æå‡äº†RAGç³»ç»Ÿçš„å¤„ç†æ•ˆç‡ï¼Œç‰¹åˆ«é€‚åˆå¤„ç†å¤§è§„æ¨¡contextçš„åœºæ™¯ã€‚è™½ç„¶åœ¨æŸäº›ç»†èŠ‚å¤„ç†ä¸Šå¯èƒ½ä¸å¦‚Refineç­–ç•¥ç²¾ç»†ï¼Œä½†å…¶å‡ºè‰²çš„æ€§èƒ½è¡¨ç°å’Œè‰¯å¥½çš„å¯æ‰©å±•æ€§ä½¿å…¶æˆä¸ºç”Ÿäº§ç¯å¢ƒä¸­çš„ä¼˜é€‰æ–¹æ¡ˆã€‚

### æ ¸å¿ƒä»·å€¼

1. **æ˜¾è‘—çš„æ€§èƒ½æå‡**ï¼š4-8å€çš„å¤„ç†é€Ÿåº¦æå‡
2. **è‰¯å¥½çš„å¯æ‰©å±•æ€§**ï¼šå¯æ ¹æ®æ•°æ®è§„æ¨¡çµæ´»è°ƒæ•´
3. **èµ„æºåˆ©ç”¨æ•ˆç‡**ï¼šå……åˆ†åˆ©ç”¨ç°ä»£è®¡ç®—èµ„æº
4. **å®ç”¨çš„å·¥ç¨‹è§£å†³æ–¹æ¡ˆ**ï¼šå¹³è¡¡äº†æ€§èƒ½å’Œè´¨é‡çš„éœ€æ±‚ 